{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui as gui\n",
    "gui.PAUSE = 1\n",
    "import numpy as np\n",
    "gui.FAILSAFE = True\n",
    "import random\n",
    "import time\n",
    "import mouse as ms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import variable\n",
    "import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 7\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = gui.getWindow('BlueStacks')\n",
    "pos = game.get_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 23, 380, 686)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = pos[2] - pos[0]\n",
    "ht = pos[3] - pos[1]\n",
    "replay_x = pos[0] + int(ln*0.4940)\n",
    "replay_y = pos[1] + int(ht*0.7194)\n",
    "play_x = pos[0] + int(0.5*ln)\n",
    "play_y = pos[1] + int(0.8733*ht)\n",
    "red_check_x = int(np.round(pos[0] + ln*0.757485))\n",
    "red_check_y = int(np.round(pos[1] + ht*0.54901))\n",
    "red_sq_ln = 0.12574*ln\n",
    "red_sq_ht = 0.063348*ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay():\n",
    "    replay_state = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(12,22))\n",
    "    ms.move(replay_x,replay_y)\n",
    "    ms.click()\n",
    "    time.sleep(0.7)\n",
    "    ms.click()\n",
    "    return replay_state\n",
    "\n",
    "def press():\n",
    "    ms.move(play_x,play_y)\n",
    "    ms.press()\n",
    "\n",
    "def release():\n",
    "    ms.move(play_x,play_y)\n",
    "    ms.release()\n",
    "\n",
    "def action(i):\n",
    "    if i == 1:\n",
    "        press()\n",
    "    if i == 0:\n",
    "        release()\n",
    "        \n",
    "def isdone():\n",
    "    red_sq = gui.grab(region=(red_check_x,red_check_y,red_sq_ln,red_sq_ht))\n",
    "    if (np.array(red_sq)[0][12][0] > 100) & (np.array(red_sq)[0][12][1] < 10):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def reset():\n",
    "    ms.release()\n",
    "    ms.move(int(pos[0]+np.round(ln*0.82035)),int(pos[1]+np.round(ht*0.11463)))\n",
    "    ms.click()\n",
    "    time.sleep(0.5)\n",
    "    ms.move(int(pos[0]+np.round(ln*0.365269)),int(pos[1]+np.round(ht*0.71040)))\n",
    "    ms.click()\n",
    "    time.sleep(0.2)\n",
    "    ms.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(i):\n",
    "    image_before = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(12,22))\n",
    "    if i == 1:\n",
    "        if ms.is_pressed() == False:\n",
    "            action(1)\n",
    "    elif i == 0:\n",
    "        if ms.is_pressed():\n",
    "            action(0)\n",
    "    #image_after = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(12,22))\n",
    "    #if isdone() == False:\n",
    "    #    reward = 1\n",
    "    #else:\n",
    "    #    reward = 0\n",
    "    return image_before,isdone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049777984619140625\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "i = 1\n",
    "reward = 0\n",
    "image_before = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(12,22))\n",
    "if i == 1:\n",
    "    if ms.is_pressed() == False:\n",
    "        action(1)\n",
    "elif i == 0:\n",
    "    if ms.is_pressed():\n",
    "        action(0)\n",
    "#image_after = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(12,22))\n",
    "#if isdone() == False:\n",
    "#    reward = 1\n",
    "#else:\n",
    "#    reward = 0\n",
    "#return image_before,reward,isdone(),image_after\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_channel,output_channel):\n",
    "        self.input_channel = input_channel\n",
    "        self.output_channel = output_channel\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channel,32,3,padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32,32,3,padding=0)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "#        self.res1 = resnet.BasicBlock(32,32)\n",
    "#        self.res2 = resnet.BasicBlock(32,32)\n",
    "#        self.res3 = resnet.BasicBlock(32,32)\n",
    "#        self.res4 = resnet.BasicBlock(32,32)\n",
    "#        self.res5 = resnet.BasicBlock(32,32)\n",
    "#        self.res6 = resnet.BasicBlock(32,32)\n",
    "#        self.res7 = resnet.BasicBlock(32,32)\n",
    "#        self.res8 = resnet.BasicBlock(32,32)\n",
    "#        self.res9 = resnet.BasicBlock(32,32)\n",
    "#        self.res10 = resnet.BasicBlock(32,32)\n",
    "        \n",
    "        \n",
    "        self.conv5 = nn.Conv2d(32,16,3)\n",
    "        self.batch_norm5 = nn.BatchNorm2d(16)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(16,1,3)\n",
    "        self.batch_norm6 = nn.BatchNorm2d(1)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(56,output_channel)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.relu1(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.relu2(self.batch_norm2(self.conv2(x)))\n",
    "#        x = self.res1(x)\n",
    "#        x = self.res2(x)\n",
    "#        x = self.res3(x)\n",
    "#        x = self.res4(x)\n",
    "#        x = self.res5(x)\n",
    "#        x = self.res6(x)\n",
    "#        x = self.res7(x)\n",
    "#        x = self.res8(x)\n",
    "#        x = self.res9(x)\n",
    "#        x = self.res10(x)\n",
    "        x = self.relu5(self.batch_norm5(self.conv5(x)))\n",
    "        x = self.relu6(self.batch_norm6(self.conv6(x)))\n",
    "        x = x.view(-1,56)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.613802671432495\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for i in range(60):\n",
    "    \n",
    "    state,is_done = step(random.choice([1,0]))\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "state = replay()\n",
    "state = state/255\n",
    "state_batch = [np.zeros((22,12))]*6\n",
    "state_batch.append(state)\n",
    "photo = []\n",
    "act = []\n",
    "sm = nn.Softmax(dim=1)\n",
    "for i in range(60):\n",
    "    move_probs = sm(net(torch.cuda.FloatTensor(state_batch).view(-1,7,22,12))).tolist()[0]\n",
    "    probs=np.array(move_probs)\n",
    "    move = np.random.choice([0,1],p=probs/sum(probs))\n",
    "    state,is_done = step(move)\n",
    "    state_batch.pop(0)\n",
    "    state_batch.append(state)\n",
    "    photo.append(state)\n",
    "    act.append(move)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.553325414657593"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Net(input_size,output_size)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "epsilon = 0.1\n",
    "while True:\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    state = replay()\n",
    "    state = state/255\n",
    "    state_batch = [np.zeros((22,12))]*6\n",
    "    state_batch.append(state)\n",
    "#    reward = 0\n",
    "#    episode_reward = 0\n",
    "    stuck_list = []\n",
    "    training_obs = []\n",
    "    training_acts = []\n",
    "    while True:\n",
    "        move_probs = sm(net(torch.cuda.FloatTensor(state_batch).view(-1,7,22,12))).tolist()[0]\n",
    "        probs=np.array(move_probs)\n",
    "        move = np.random.choice([0,1],p=probs/sum(probs))\n",
    "#        move = np.random.choice([move,np.abs(1-move)],p=[1-epsilon,epsilon])\n",
    "        state,is_done = step(move)\n",
    "        state_batch.pop(0)\n",
    "        state_batch.append(state)\n",
    "#        episode_reward += reward\n",
    "        training_obs.append(state)\n",
    "        training_acts.append(move)\n",
    "        stuck_image = gui.grab(region=(pos[0],pos[1],int(ln),int(ht/2)))\n",
    "        stuck_list.append(stuck_image)\n",
    "        if isdone():\n",
    "            ms.release()\n",
    "#            training_obs = training_obs[0:-2]\n",
    "            training_acts_opposite = list(1 - np.array(training_acts[-3:]))\n",
    "            training_acts = training_acts[0:-3]\n",
    "            training_acts.extend(training_acts_opposite)\n",
    "            \n",
    "            if len(training_acts) > 100:\n",
    "                print('training')\n",
    "                training_obs_v = torch.cuda.FloatTensor(np.array(training_obs[:98])/255)\n",
    "                training_acts_v = torch.cuda.FloatTensor(np.array(training_acts[:98]))\n",
    "                obs_batch = training_obs_v[:7]\n",
    "                del training_acts_v[:6]\n",
    "                act_batch = training_acts_v[0]\n",
    "                for i in range(14):\n",
    "                    action_scores_v = net(obs_batch.view(-1,7, 110, 60))\n",
    "                    loss_v = objective(action_scores_v, variable(act_batch).long())\n",
    "                    loss_v.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    print('loss '+ str(loss_v.item()))\n",
    "                    del training_acts_v[0]\n",
    "                    del training_obs_v[0]\n",
    "                training_obs = training_obs[98:]\n",
    "                training_acts = training_acts[98:]\n",
    "                \n",
    "#                episode_reward = 0\n",
    "            replay()\n",
    "        else:\n",
    "            if stuck_list.count(stuck_image)>25:\n",
    "                ms.release()\n",
    "                print('stucked ' + str(episode_reward))\n",
    "#                episode_reward = 0\n",
    "                reset()\n",
    "                stuck_list = []\n",
    "                training_obs = []\n",
    "                training_acts = []\n",
    "#    if episode_reward > 100:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:167: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (7).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-7adf0e19563a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_scores_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 862\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1550\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1403\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[1;32m-> 1405\u001b[1;33m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[0;32m   1406\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (7)."
     ]
    }
   ],
   "source": [
    "objective(action_scores_v, variable(act_batch).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_acts_opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
